{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'flower-data/train/'\n",
    "valid_dir = 'flower-data/val/'\n",
    "test_dir = 'flower-data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_sz = 256\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45492 images belonging to 104 classes.\n",
      "Found 12157 images belonging to 104 classes.\n"
     ]
    }
   ],
   "source": [
    "datagenerator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    horizontal_flip=True,\n",
    "\n",
    ")\n",
    "\n",
    "train_gen = datagenerator.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(img_sz,img_sz),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    ")\n",
    "valid_gen = datagenerator.flow_from_directory(\n",
    "    directory=valid_dir,\n",
    "    target_size=(img_sz,img_sz),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpine sea holly', 'anthurium', 'artichoke', 'azalea', 'balloon flower', 'barberton daisy', 'bee balm', 'bird of paradise', 'bishop of llandaff', 'black-eyed susan', 'blackberry lily', 'blanket flower', 'bolero deep blue', 'bougainvillea', 'bromelia', 'buttercup', 'californian poppy', 'camellia', 'canna lily', 'canterbury bells', 'cape flower', 'carnation', 'cautleya spicata', 'clematis', 'colt foot', 'columbine', 'common dandelion', 'common tulip', 'corn poppy', 'cosmos', 'cyclamen', 'daffodil', 'daisy', 'desert-rose', 'fire lily', 'foxglove', 'frangipani', 'fritillary', 'garden phlox', 'gaura', 'gazania', 'geranium', 'giant white arum lily', 'globe thistle', 'globe-flower', 'grape hyacinth', 'great masterwort', 'hard-leaved pocket orchid', 'hibiscus', 'hippeastrum', 'iris', 'japanese anemone', 'king protea', 'lenten rose', 'lilac hibiscus', 'lotus', 'love in the mist', 'magnolia', 'mallow', 'marigold', 'mexican petunia', 'monkshood', 'moon orchid', 'morning glory', 'orange dahlia', 'osteospermum', 'passion flower', 'peruvian lily', 'petunia', 'pincushion flower', 'pink primrose', 'pink quill', 'pink-yellow dahlia', 'poinsettia', 'primula', 'prince of wales feathers', 'purple coneflower', 'red ginger', 'rose', 'ruby-lipped cattleya', 'siam tulip', 'silverbush', 'snapdragon', 'spear thistle', 'spring crocus', 'stemless gentian', 'sunflower', 'sweet pea', 'sweet william', 'sword lily', 'thorn apple', 'tiger lily', 'toad lily', 'tree mallow', 'tree poppy', 'trumpet creeper', 'wallflower', 'water lily', 'watercress', 'wild geranium', 'wild pansy', 'wild rose', 'windflower', 'yellow iris'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "['alpine sea holly', 'anthurium', 'artichoke', 'azalea', 'balloon flower', 'barberton daisy', 'bee balm', 'bird of paradise', 'bishop of llandaff', 'black-eyed susan', 'blackberry lily', 'blanket flower', 'bolero deep blue', 'bougainvillea', 'bromelia', 'buttercup', 'californian poppy', 'camellia', 'canna lily', 'canterbury bells', 'cape flower', 'carnation', 'cautleya spicata', 'clematis', 'colt foot', 'columbine', 'common dandelion', 'common tulip', 'corn poppy', 'cosmos', 'cyclamen', 'daffodil', 'daisy', 'desert-rose', 'fire lily', 'foxglove', 'frangipani', 'fritillary', 'garden phlox', 'gaura', 'gazania', 'geranium', 'giant white arum lily', 'globe thistle', 'globe-flower', 'grape hyacinth', 'great masterwort', 'hard-leaved pocket orchid', 'hibiscus', 'hippeastrum', 'iris', 'japanese anemone', 'king protea', 'lenten rose', 'lilac hibiscus', 'lotus', 'love in the mist', 'magnolia', 'mallow', 'marigold', 'mexican petunia', 'monkshood', 'moon orchid', 'morning glory', 'orange dahlia', 'osteospermum', 'passion flower', 'peruvian lily', 'petunia', 'pincushion flower', 'pink primrose', 'pink quill', 'pink-yellow dahlia', 'poinsettia', 'primula', 'prince of wales feathers', 'purple coneflower', 'red ginger', 'rose', 'ruby-lipped cattleya', 'siam tulip', 'silverbush', 'snapdragon', 'spear thistle', 'spring crocus', 'stemless gentian', 'sunflower', 'sweet pea', 'sweet william', 'sword lily', 'thorn apple', 'tiger lily', 'toad lily', 'tree mallow', 'tree poppy', 'trumpet creeper', 'wallflower', 'water lily', 'watercress', 'wild geranium', 'wild pansy', 'wild rose', 'windflower', 'yellow iris']\n"
     ]
    }
   ],
   "source": [
    "num_of_classes = len(os.listdir(train_dir))\n",
    "print(num_of_classes)\n",
    "class_names = list(train_gen.class_indices.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.30967763 0.23780325 0.11494847]\n",
      "  [0.3458953  0.26118293 0.13059147]\n",
      "  [0.38183692 0.27415892 0.13083592]\n",
      "  ...\n",
      "  [0.34773028 0.25882354 0.11240938]\n",
      "  [0.34901804 0.25882354 0.11176551]\n",
      "  [0.35030577 0.25882354 0.11112165]]\n",
      "\n",
      " [[0.3019512  0.23136458 0.10979753]\n",
      "  [0.34074435 0.25860748 0.12930374]\n",
      "  [0.37539825 0.27222732 0.13147978]\n",
      "  ...\n",
      "  [0.3491525  0.25503483 0.10854103]\n",
      "  [0.3472209  0.25310323 0.10789716]\n",
      "  [0.3452893  0.25117165 0.10725329]]\n",
      "\n",
      " [[0.2942248  0.2249259  0.1046466 ]\n",
      "  [0.33559343 0.256032   0.128016  ]\n",
      "  [0.36895958 0.27029574 0.13212366]\n",
      "  ...\n",
      "  [0.3399668  0.24584916 0.10467267]\n",
      "  [0.33932292 0.24520528 0.10402881]\n",
      "  [0.33867908 0.24456142 0.10338494]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0926935  0.12798762 0.04563467]\n",
      "  [0.09204963 0.12734376 0.04499081]\n",
      "  [0.09140577 0.12669988 0.04434694]\n",
      "  ...\n",
      "  [0.42085713 0.36324328 0.20304401]\n",
      "  [0.41987363 0.35041538 0.22140223]\n",
      "  [0.43266192 0.35554665 0.25092682]]\n",
      "\n",
      " [[0.08745421 0.12686113 0.04039539]\n",
      "  [0.08616648 0.127505   0.03910765]\n",
      "  [0.08487875 0.12814887 0.03781992]\n",
      "  ...\n",
      "  [0.4298713  0.3729013  0.20883882]\n",
      "  [0.4160104  0.34912768 0.21431969]\n",
      "  [0.43137416 0.3549028  0.24706364]]\n",
      "\n",
      " [[0.08103523 0.12809406 0.0339764 ]\n",
      "  [0.08039136 0.1274502  0.03333253]\n",
      "  [0.07974749 0.12680632 0.03268867]\n",
      "  ...\n",
      "  [0.4388854  0.3825593  0.21463363]\n",
      "  [0.4121472  0.34783992 0.20723715]\n",
      "  [0.43008643 0.35425892 0.24320042]]]\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for image_batch, label_batch in train_gen:\n",
    "    print(image_batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=.001)\n",
    "epochs = 10\n",
    "checkpoint =tf.keras.callbacks.ModelCheckpoint(f'model{epochs}epochs.h5',\n",
    "                                               monitor='val_loss',\n",
    "                                               mode='min',\n",
    "                                               save_best_only=True,\n",
    "                                               verbose=1)\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                             min_delta=0,\n",
    "                                             patience=50,\n",
    "                                             verbose=1,restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint,earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(img_sz,img_sz, 3)),\n",
    "  layers.MaxPooling2D((2,2)),\n",
    "\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D((2,2)),\n",
    "\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D((2,2)),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_of_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 65536)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8388736   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 104)               13416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,425,736\n",
      "Trainable params: 8,425,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1421/1421 [==============================] - ETA: 0s - loss: 2.9449 - accuracy: 0.2619\n",
      "Epoch 1: val_loss improved from inf to 2.59954, saving model to model10epochs.h5\n",
      "1421/1421 [==============================] - 1147s 801ms/step - loss: 2.9449 - accuracy: 0.2619 - val_loss: 2.5995 - val_accuracy: 0.3265\n",
      "Epoch 2/10\n",
      "1421/1421 [==============================] - ETA: 0s - loss: 1.8089 - accuracy: 0.5123\n",
      "Epoch 2: val_loss improved from 2.59954 to 2.48207, saving model to model10epochs.h5\n",
      "1421/1421 [==============================] - 1131s 796ms/step - loss: 1.8089 - accuracy: 0.5123 - val_loss: 2.4821 - val_accuracy: 0.3817\n",
      "Epoch 3/10\n",
      "1421/1421 [==============================] - ETA: 0s - loss: 1.1996 - accuracy: 0.6686\n",
      "Epoch 3: val_loss did not improve from 2.48207\n",
      "1421/1421 [==============================] - 1366s 961ms/step - loss: 1.1996 - accuracy: 0.6686 - val_loss: 2.6462 - val_accuracy: 0.4100\n",
      "Epoch 4/10\n",
      "1421/1421 [==============================] - ETA: 0s - loss: 0.8149 - accuracy: 0.7709\n",
      "Epoch 4: val_loss did not improve from 2.48207\n",
      "1421/1421 [==============================] - 1000s 704ms/step - loss: 0.8149 - accuracy: 0.7709 - val_loss: 2.9370 - val_accuracy: 0.4039\n",
      "Epoch 5/10\n",
      "1421/1421 [==============================] - ETA: 0s - loss: 0.5835 - accuracy: 0.8331\n",
      "Epoch 5: val_loss did not improve from 2.48207\n",
      "1421/1421 [==============================] - 1150s 810ms/step - loss: 0.5835 - accuracy: 0.8331 - val_loss: 3.3283 - val_accuracy: 0.4035\n",
      "Epoch 6/10\n",
      "1421/1421 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.8750\n",
      "Epoch 6: val_loss did not improve from 2.48207\n",
      "1421/1421 [==============================] - 1428s 1s/step - loss: 0.4339 - accuracy: 0.8750 - val_loss: 3.7279 - val_accuracy: 0.3876\n",
      "Epoch 7/10\n",
      "1421/1421 [==============================] - ETA: 0s - loss: 0.3341 - accuracy: 0.9012\n",
      "Epoch 7: val_loss did not improve from 2.48207\n",
      "1421/1421 [==============================] - 1324s 931ms/step - loss: 0.3341 - accuracy: 0.9012 - val_loss: 3.8826 - val_accuracy: 0.4002\n",
      "Epoch 8/10\n",
      "1421/1421 [==============================] - ETA: 0s - loss: 0.2796 - accuracy: 0.9178\n",
      "Epoch 8: val_loss did not improve from 2.48207\n",
      "1421/1421 [==============================] - 1071s 753ms/step - loss: 0.2796 - accuracy: 0.9178 - val_loss: 4.4101 - val_accuracy: 0.4005\n",
      "Epoch 9/10\n",
      "1421/1421 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.9263\n",
      "Epoch 9: val_loss did not improve from 2.48207\n",
      "1421/1421 [==============================] - 1039s 731ms/step - loss: 0.2479 - accuracy: 0.9263 - val_loss: 4.6150 - val_accuracy: 0.3943\n",
      "Epoch 10/10\n",
      "1421/1421 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9345\n",
      "Epoch 10: val_loss did not improve from 2.48207\n",
      "1421/1421 [==============================] - 1024s 720ms/step - loss: 0.2199 - accuracy: 0.9345 - val_loss: 4.8582 - val_accuracy: 0.4001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data = valid_gen,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch = train_gen.samples//batch_size,\n",
    "    validation_steps = valid_gen.samples//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 198s 521ms/step - loss: 4.8301 - accuracy: 0.3919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.830072402954102, 0.39187300205230713]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
